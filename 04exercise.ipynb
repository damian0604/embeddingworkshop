{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Monday\n",
    "\n",
    "Train your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import string\n",
    "import re\n",
    "\n",
    "# tqdm allows you to display progress bars in loops\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# you need to have courseutils.py in the same folder\n",
    "from courseutils import get_review_data\n",
    "\n",
    "import gensim\n",
    "\n",
    "# lets get more output\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that there are some slight syntax changes between gensim 3 and 4; notebook is now optimized for gensim 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get a lot of texts\n",
    "\n",
    "I'll just take the movie reviews here, but you are *very much encouraged* to take your own data. Use any method to get them into a long list (or similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached file reviewdata.pickle.bz2\n"
     ]
    }
   ],
   "source": [
    "train, test, _, _ = get_review_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset has two sets of reviews of length 25000 and 25000\n",
      "We merged them into one list of 50000 reviews\n"
     ]
    }
   ],
   "source": [
    "# we just need one list\n",
    "print(f\"The original dataset has two sets of reviews of length {len(train)} and {len(test)}\")\n",
    "train.extend(test)\n",
    "del test\n",
    "print(f\"We merged them into one list of {len(train)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " '\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.',\n",
       " \"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Reformat\n",
    "We want to train on sentences, not on whole reviews. We don't need a list of reviews, but a list of sentences.\n",
    "\n",
    "Also, **we only want unique sentences**. It has been shown that this improves the resulting models (and it speeds up training, of course).\n",
    "\n",
    "There are different ways of achieving this, here is one. Some remarks:\n",
    "\n",
    "- tqdm displays a progress bar - it's not strictly necessary\n",
    "- a set is like a list without order, and all items are guaranteed to be unique. You could also use a list, but this is faster. Then, you need to use `uniquesentences = []` and `.append()` instead of `.add()`\n",
    "- we also remove punctuation \n",
    "- depending on whether the texts we want to use our model on later on are lowercased or not, we have to (or not) lowercase here as well. That's a decision to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:33<00:00, 1471.57it/s]\n"
     ]
    }
   ],
   "source": [
    "trans = str.maketrans('', '', string.punctuation) # translation scheme for removing punctuation\n",
    "uniquesentences = set()\n",
    "for review in tqdm(train):\n",
    "    for sentence in sent_tokenize(review):\n",
    "        # remove HTML tags in there\n",
    "        sentence = re.sub(r\"<.*?>\",\" \",sentence)\n",
    "        sentence = sentence.translate(trans) \n",
    "        if sentence not in uniquesentences:\n",
    "            uniquesentences.add(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 516343 unique sentences.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We now have {len(uniquesentences)} unique sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to, we can turn the set into a list and expect it, e.g. like this:\n",
    "# list(uniquesentences)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that unqiesentences can be also a generator that reads from disk (or from elsewhere) for the next step. Hence, it is possible to train models on more sentences than fit in your memory!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the model\n",
    "\n",
    "That's really straightforward in gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need a list of lists of tokens later on, so let's use a generator instead of a list to save memory\n",
    "# note that we use round parentheses instead of square brackets to achieve this\n",
    "# we do need two generators, though, as we first need to build the vocabulary and later need to train.\n",
    "# If we use a list, we obviously only need once.\n",
    "tokenizedsentences = (sentence.split() for sentence in uniquesentences)\n",
    "tokenizedsentences2 = (sentence.split() for sentence in uniquesentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 15:13:23,112 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.025)', 'datetime': '2021-04-12T15:13:23.068712', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "2021-04-12 15:13:23,113 : INFO : collecting all words and their counts\n",
      "2021-04-12 15:13:23,116 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started setting up the model at 2021-04-12 15:13:23.067450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 15:13:23,235 : INFO : PROGRESS: at sentence #10000, processed 218529 words, keeping 20717 word types\n",
      "2021-04-12 15:13:23,357 : INFO : PROGRESS: at sentence #20000, processed 435537 words, keeping 30405 word types\n",
      "2021-04-12 15:13:23,505 : INFO : PROGRESS: at sentence #30000, processed 653899 words, keeping 37751 word types\n",
      "2021-04-12 15:13:23,627 : INFO : PROGRESS: at sentence #40000, processed 875468 words, keeping 43880 word types\n",
      "2021-04-12 15:13:23,739 : INFO : PROGRESS: at sentence #50000, processed 1094762 words, keeping 49271 word types\n",
      "2021-04-12 15:13:23,855 : INFO : PROGRESS: at sentence #60000, processed 1315483 words, keeping 54105 word types\n",
      "2021-04-12 15:13:23,984 : INFO : PROGRESS: at sentence #70000, processed 1534805 words, keeping 58617 word types\n",
      "2021-04-12 15:13:24,096 : INFO : PROGRESS: at sentence #80000, processed 1749939 words, keeping 62565 word types\n",
      "2021-04-12 15:13:24,217 : INFO : PROGRESS: at sentence #90000, processed 1965987 words, keeping 66432 word types\n",
      "2021-04-12 15:13:24,423 : INFO : PROGRESS: at sentence #100000, processed 2181551 words, keeping 70068 word types\n",
      "2021-04-12 15:13:24,532 : INFO : PROGRESS: at sentence #110000, processed 2399403 words, keeping 73387 word types\n",
      "2021-04-12 15:13:24,639 : INFO : PROGRESS: at sentence #120000, processed 2617231 words, keeping 76678 word types\n",
      "2021-04-12 15:13:24,735 : INFO : PROGRESS: at sentence #130000, processed 2836129 words, keeping 79977 word types\n",
      "2021-04-12 15:13:24,852 : INFO : PROGRESS: at sentence #140000, processed 3055163 words, keeping 83112 word types\n",
      "2021-04-12 15:13:25,004 : INFO : PROGRESS: at sentence #150000, processed 3275445 words, keeping 86239 word types\n",
      "2021-04-12 15:13:25,138 : INFO : PROGRESS: at sentence #160000, processed 3495322 words, keeping 89272 word types\n",
      "2021-04-12 15:13:25,242 : INFO : PROGRESS: at sentence #170000, processed 3714112 words, keeping 92147 word types\n",
      "2021-04-12 15:13:25,353 : INFO : PROGRESS: at sentence #180000, processed 3934207 words, keeping 95000 word types\n",
      "2021-04-12 15:13:25,466 : INFO : PROGRESS: at sentence #190000, processed 4151518 words, keeping 97732 word types\n",
      "2021-04-12 15:13:25,602 : INFO : PROGRESS: at sentence #200000, processed 4368226 words, keeping 100310 word types\n",
      "2021-04-12 15:13:25,702 : INFO : PROGRESS: at sentence #210000, processed 4586027 words, keeping 103045 word types\n",
      "2021-04-12 15:13:25,817 : INFO : PROGRESS: at sentence #220000, processed 4804705 words, keeping 105668 word types\n",
      "2021-04-12 15:13:25,922 : INFO : PROGRESS: at sentence #230000, processed 5025426 words, keeping 108190 word types\n",
      "2021-04-12 15:13:26,047 : INFO : PROGRESS: at sentence #240000, processed 5244031 words, keeping 110765 word types\n",
      "2021-04-12 15:13:26,172 : INFO : PROGRESS: at sentence #250000, processed 5460578 words, keeping 113147 word types\n",
      "2021-04-12 15:13:26,278 : INFO : PROGRESS: at sentence #260000, processed 5679882 words, keeping 115518 word types\n",
      "2021-04-12 15:13:26,377 : INFO : PROGRESS: at sentence #270000, processed 5897614 words, keeping 117860 word types\n",
      "2021-04-12 15:13:26,475 : INFO : PROGRESS: at sentence #280000, processed 6113606 words, keeping 120209 word types\n",
      "2021-04-12 15:13:26,585 : INFO : PROGRESS: at sentence #290000, processed 6332988 words, keeping 122514 word types\n",
      "2021-04-12 15:13:26,683 : INFO : PROGRESS: at sentence #300000, processed 6549895 words, keeping 124632 word types\n",
      "2021-04-12 15:13:26,788 : INFO : PROGRESS: at sentence #310000, processed 6767327 words, keeping 126964 word types\n",
      "2021-04-12 15:13:26,899 : INFO : PROGRESS: at sentence #320000, processed 6989511 words, keeping 129319 word types\n",
      "2021-04-12 15:13:26,993 : INFO : PROGRESS: at sentence #330000, processed 7202763 words, keeping 131420 word types\n",
      "2021-04-12 15:13:27,099 : INFO : PROGRESS: at sentence #340000, processed 7421298 words, keeping 133550 word types\n",
      "2021-04-12 15:13:27,202 : INFO : PROGRESS: at sentence #350000, processed 7639214 words, keeping 135683 word types\n",
      "2021-04-12 15:13:27,331 : INFO : PROGRESS: at sentence #360000, processed 7857905 words, keeping 137728 word types\n",
      "2021-04-12 15:13:27,445 : INFO : PROGRESS: at sentence #370000, processed 8077317 words, keeping 139807 word types\n",
      "2021-04-12 15:13:27,543 : INFO : PROGRESS: at sentence #380000, processed 8296146 words, keeping 141730 word types\n",
      "2021-04-12 15:13:27,651 : INFO : PROGRESS: at sentence #390000, processed 8515296 words, keeping 143642 word types\n",
      "2021-04-12 15:13:27,756 : INFO : PROGRESS: at sentence #400000, processed 8734781 words, keeping 145684 word types\n",
      "2021-04-12 15:13:27,867 : INFO : PROGRESS: at sentence #410000, processed 8951452 words, keeping 147552 word types\n",
      "2021-04-12 15:13:27,972 : INFO : PROGRESS: at sentence #420000, processed 9170919 words, keeping 149463 word types\n",
      "2021-04-12 15:13:28,087 : INFO : PROGRESS: at sentence #430000, processed 9389537 words, keeping 151349 word types\n",
      "2021-04-12 15:13:28,195 : INFO : PROGRESS: at sentence #440000, processed 9606489 words, keeping 153167 word types\n",
      "2021-04-12 15:13:28,308 : INFO : PROGRESS: at sentence #450000, processed 9822633 words, keeping 155071 word types\n",
      "2021-04-12 15:13:28,418 : INFO : PROGRESS: at sentence #460000, processed 10042348 words, keeping 156954 word types\n",
      "2021-04-12 15:13:28,523 : INFO : PROGRESS: at sentence #470000, processed 10259943 words, keeping 158795 word types\n",
      "2021-04-12 15:13:28,638 : INFO : PROGRESS: at sentence #480000, processed 10475096 words, keeping 160617 word types\n",
      "2021-04-12 15:13:28,762 : INFO : PROGRESS: at sentence #490000, processed 10694817 words, keeping 162378 word types\n",
      "2021-04-12 15:13:28,878 : INFO : PROGRESS: at sentence #500000, processed 10913102 words, keeping 164196 word types\n",
      "2021-04-12 15:13:28,985 : INFO : PROGRESS: at sentence #510000, processed 11133411 words, keeping 166169 word types\n",
      "2021-04-12 15:13:29,046 : INFO : collected 167386 word types from a corpus of 11272631 raw words and 516343 sentences\n",
      "2021-04-12 15:13:29,048 : INFO : Creating a fresh vocabulary\n",
      "2021-04-12 15:13:29,338 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 42926 unique words (25.644916540212442%% of original 167386, drops 124460)', 'datetime': '2021-04-12T15:13:29.338327', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-04-12 15:13:29,339 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 11096425 word corpus (98.43686890842076%% of original 11272631, drops 176206)', 'datetime': '2021-04-12T15:13:29.339112', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-04-12 15:13:29,728 : INFO : deleting the raw counts dictionary of 167386 items\n",
      "2021-04-12 15:13:29,733 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2021-04-12 15:13:29,734 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 8359192.914901451 word corpus (75.3%% of prior 11096425)', 'datetime': '2021-04-12T15:13:29.734147', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "2021-04-12 15:13:30,532 : INFO : estimated required memory for 42926 words and 300 dimensions: 124485400 bytes\n",
      "2021-04-12 15:13:30,535 : INFO : resetting layer weights\n",
      "2021-04-12 15:13:30,828 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-04-12T15:13:30.828655', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "2021-04-12 15:13:30,831 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 42926 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-04-12T15:13:30.831054', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started training at 2021-04-12 15:13:30.830823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 15:13:31,842 : INFO : EPOCH 1 - PROGRESS: at 3.28% examples, 273239 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:32,868 : INFO : EPOCH 1 - PROGRESS: at 7.25% examples, 299411 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:33,873 : INFO : EPOCH 1 - PROGRESS: at 10.86% examples, 300228 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:34,901 : INFO : EPOCH 1 - PROGRESS: at 14.85% examples, 306453 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:35,948 : INFO : EPOCH 1 - PROGRESS: at 19.30% examples, 316077 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:36,970 : INFO : EPOCH 1 - PROGRESS: at 23.05% examples, 314256 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:37,974 : INFO : EPOCH 1 - PROGRESS: at 26.67% examples, 312540 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:38,998 : INFO : EPOCH 1 - PROGRESS: at 30.27% examples, 310560 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:40,008 : INFO : EPOCH 1 - PROGRESS: at 33.99% examples, 310254 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:41,019 : INFO : EPOCH 1 - PROGRESS: at 37.70% examples, 309970 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:42,021 : INFO : EPOCH 1 - PROGRESS: at 41.69% examples, 311956 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:43,040 : INFO : EPOCH 1 - PROGRESS: at 45.20% examples, 310145 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:44,041 : INFO : EPOCH 1 - PROGRESS: at 49.03% examples, 310769 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:45,048 : INFO : EPOCH 1 - PROGRESS: at 52.57% examples, 309601 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:46,081 : INFO : EPOCH 1 - PROGRESS: at 55.60% examples, 305084 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:47,083 : INFO : EPOCH 1 - PROGRESS: at 58.80% examples, 302662 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:48,113 : INFO : EPOCH 1 - PROGRESS: at 62.86% examples, 304351 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:49,134 : INFO : EPOCH 1 - PROGRESS: at 66.61% examples, 304373 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:50,139 : INFO : EPOCH 1 - PROGRESS: at 70.69% examples, 306184 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:51,190 : INFO : EPOCH 1 - PROGRESS: at 74.39% examples, 305637 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:52,201 : INFO : EPOCH 1 - PROGRESS: at 76.77% examples, 300511 words/s, in_qsize 6, out_qsize 0\n",
      "2021-04-12 15:13:53,201 : INFO : EPOCH 1 - PROGRESS: at 79.61% examples, 297650 words/s, in_qsize 6, out_qsize 2\n",
      "2021-04-12 15:13:54,210 : INFO : EPOCH 1 - PROGRESS: at 83.23% examples, 297786 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:55,269 : INFO : EPOCH 1 - PROGRESS: at 86.25% examples, 295187 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:56,290 : INFO : EPOCH 1 - PROGRESS: at 89.01% examples, 292346 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:57,296 : INFO : EPOCH 1 - PROGRESS: at 92.57% examples, 292422 words/s, in_qsize 5, out_qsize 0\n",
      "2021-04-12 15:13:58,326 : INFO : EPOCH 1 - PROGRESS: at 95.40% examples, 290091 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:59,384 : INFO : EPOCH 1 - PROGRESS: at 98.21% examples, 287649 words/s, in_qsize 6, out_qsize 1\n",
      "2021-04-12 15:13:59,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-04-12 15:13:59,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-04-12 15:13:59,910 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-04-12 15:13:59,913 : INFO : EPOCH - 1 : training on 11272631 raw words (8359864 effective words) took 29.1s, 287537 effective words/s\n",
      "2021-04-12 15:13:59,916 : INFO : Word2Vec lifecycle event {'msg': 'training on 11272631 raw words (8359864 effective words) took 29.1s, 287438 effective words/s', 'datetime': '2021-04-12T15:13:59.916033', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training at 2021-04-12 15:13:59.920354\n"
     ]
    }
   ],
   "source": [
    "print(f\"Started setting up the model at {datetime.now()}\")\n",
    "model = gensim.models.Word2Vec(vector_size=300) # we want 300 dimensions\n",
    "model.build_vocab(tokenizedsentences)\n",
    "print(f\"Started training at {datetime.now()}\")\n",
    "model.train(tokenizedsentences2, total_examples=model.corpus_count,  epochs=1)\n",
    "# our model gets better if we use more epochs, but we can only do so if we use a list instead of a generator as input\n",
    "# after all, you can only pass over a generator once.\n",
    "# model.train(tokenizedsentences2, total_examples=model.corpus_count,  epochs=model.epochs)\n",
    "print(f\"Finished training at {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 15:14:00,041 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'mymodel', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-04-12T15:14:00.041830', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "2021-04-12 15:14:00,044 : INFO : storing np array 'vectors' to mymodel.wv.vectors.npy\n",
      "2021-04-12 15:14:00,281 : INFO : storing np array 'syn1neg' to mymodel.syn1neg.npy\n",
      "2021-04-12 15:14:00,583 : INFO : not storing attribute cum_table\n",
      "2021-04-12 15:14:00,630 : INFO : saved mymodel\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mymodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-12 15:14:00,639 : INFO : loading Word2Vec object from mymodel\n",
      "2021-04-12 15:14:00,661 : INFO : loading wv recursively from mymodel.wv.* with mmap=None\n",
      "2021-04-12 15:14:00,662 : INFO : loading vectors from mymodel.wv.vectors.npy with mmap=None\n",
      "2021-04-12 15:14:00,782 : INFO : loading syn1neg from mymodel.syn1neg.npy with mmap=None\n",
      "2021-04-12 15:14:00,977 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-12 15:14:02,067 : INFO : Word2Vec lifecycle event {'fname': 'mymodel', 'datetime': '2021-04-12T15:14:02.067166', 'gensim': '4.0.1', 'python': '3.8.5 (default, Jan 27 2021, 15:41:15) \\n[GCC 9.3.0]', 'platform': 'Linux-5.4.0-70-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# and load it again, just to check\n",
    "mymodel = gensim.models.Word2Vec.load(\"mymodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Play with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat is almost the same as a horse.\n",
      "A dog is almost the same as a baby.\n",
      "A horse is almost the same as a cat.\n",
      "A goldfish is almost the same as a sugar.\n",
      "A lion is almost the same as a rueda.\n"
     ]
    }
   ],
   "source": [
    "animals = ['cat', 'dog', 'horse', 'goldfish', 'lion']\n",
    "for animal in animals:\n",
    "    try:\n",
    "        print(f\"A {animal} is almost the same as a {model.wv.most_similar(animal)[0][0]}.\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A director is almost the same as a writer.\n",
      "A actor is almost the same as a actress.\n",
      "A bad is almost the same as a good.\n",
      "A good is almost the same as a bad.\n"
     ]
    }
   ],
   "source": [
    "animals = ['director', 'actor', 'bad', 'good']\n",
    "for animal in animals:\n",
    "    try:\n",
    "        print(f\"A {animal} is almost the same as a {model.wv.most_similar(animal)[0][0]}.\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suspense', 0.7984694242477417),\n",
       " ('gore', 0.7710525393486023),\n",
       " ('cheap', 0.7398205995559692),\n",
       " ('humor', 0.7144436240196228),\n",
       " ('mood', 0.7109081149101257),\n",
       " ('atmosphere', 0.7079086899757385),\n",
       " ('cheesy', 0.7015352845191956),\n",
       " ('violence', 0.7014023065567017),\n",
       " ('slasher', 0.698836088180542),\n",
       " ('music', 0.6971469521522522)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 0.9301337599754333),\n",
       " ('show', 0.7778735756874084),\n",
       " ('flick', 0.7578645944595337),\n",
       " ('documentary', 0.7446282505989075),\n",
       " ('picture', 0.7295028567314148),\n",
       " ('sequel', 0.7083451747894287),\n",
       " ('series', 0.7011323571205139),\n",
       " ('episode', 0.6649038195610046),\n",
       " ('it', 0.6541301608085632),\n",
       " ('movies', 0.6459987163543701)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Adapt\n",
    "\n",
    "Now it's time to dive into the gensim documentation (online or via `?` / tab completion) to figure out the options you have - e.g., skipgram vs CBOW, dimensions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.models.Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
